{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9459446,"sourceType":"datasetVersion","datasetId":5750706}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom collections import Counter\n\n# Download necessary NLTK data\nnltk.download('stopwords')\n\n# Load the dataset\ndf = pd.read_csv('/kaggle/input/satrain/train.csv')  # Modify path if necessary\n\n# Define the stopwords to keep, e.g., \"not\" and other sentiment-related words\nsentiment_stopwords = {'not', 'never', 'dont', 'cant', 'wont', 'no'}\nstop_words = set(stopwords.words('english')) - sentiment_stopwords\n\n# Function to clean text data\ndef clean_text(text):\n    # Remove non-alphabetical characters\n    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n    \n    # Convert text to lowercase\n    text = text.lower()\n    \n    # Tokenize and remove stop words except those kept for sentiment\n    words = [word for word in text.split() if word not in stop_words]\n    \n    return ' '.join(words)\n\n# Apply text cleaning to the 'text' column\ndf['cleaned_text'] = df['text'].apply(clean_text)\n\n# Count the frequency of all words in the dataset\nword_counts = Counter(' '.join(df['cleaned_text']).split())\n\n# Find words that appear more than 3 times\ncommon_words = {word for word, count in word_counts.items() if count > 3}\n\n# Function to remove infrequent words from text\ndef remove_infrequent_words(text):\n    words = text.split()\n    words_filtered = [word for word in words if word in common_words]\n    return ' '.join(words_filtered)\n\n# Apply the function to remove infrequent words\ndf['final_text'] = df['cleaned_text'].apply(remove_infrequent_words)\n\n# Save removed words to a CSV file\nremoved_words = {word for word, count in word_counts.items() if count <= 3}\nremoved_words_df = pd.DataFrame(removed_words, columns=['removed_word'])\nremoved_words_df.to_csv('removedwords.csv', index=False)\n\n# Save the final cleaned dataset to a new CSV file\ndf[['final_text', 'class']].to_csv('cleaned_train.csv', index=False)\n\nprint(\"Preprocessing completed. Files saved: 'cleaned_train.csv' and 'removedwords.csv'.\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-23T04:35:40.451268Z","iopub.execute_input":"2024-09-23T04:35:40.451806Z","iopub.status.idle":"2024-09-23T04:37:31.219884Z","shell.execute_reply.started":"2024-09-23T04:35:40.451738Z","shell.execute_reply":"2024-09-23T04:37:31.218119Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\nPreprocessing completed. Files saved: 'cleaned_train.csv' and 'removedwords.csv'.\n","output_type":"stream"}]}]}