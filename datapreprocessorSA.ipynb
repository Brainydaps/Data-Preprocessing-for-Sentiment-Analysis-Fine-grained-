{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/adedapoadeniran/data-preprocessing-for-sentiment-analysis?scriptVersionId=197869200\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":1,"id":"c225d42f","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-09-23T04:46:47.938521Z","iopub.status.busy":"2024-09-23T04:46:47.938068Z","iopub.status.idle":"2024-09-23T04:48:32.17498Z","shell.execute_reply":"2024-09-23T04:48:32.173324Z"},"papermill":{"duration":104.244261,"end_time":"2024-09-23T04:48:32.17823","exception":false,"start_time":"2024-09-23T04:46:47.933969","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","Preprocessing completed. Files saved: 'cleaned_train.csv' and 'removedwords.csv'.\n"]}],"source":["import pandas as pd\n","import re\n","import nltk\n","from nltk.corpus import stopwords\n","from collections import Counter\n","\n","# Download necessary NLTK data\n","nltk.download('stopwords')\n","\n","# Load the dataset\n","df = pd.read_csv('/kaggle/input/satrain/train.csv')  # Modify path if necessary\n","\n","# Define the stopwords to keep, e.g., \"not\" and other sentiment-related words\n","sentiment_stopwords = {'not', 'never', 'dont', 'cant', 'wont', 'no'}\n","stop_words = set(stopwords.words('english')) - sentiment_stopwords\n","\n","# Function to clean text data\n","def clean_text(text):\n","    # Remove non-alphabetical characters\n","    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n","    \n","    # Convert text to lowercase\n","    text = text.lower()\n","    \n","    # Tokenize and remove stop words except those kept for sentiment\n","    words = [word for word in text.split() if word not in stop_words]\n","    \n","    return ' '.join(words)\n","\n","# Apply text cleaning to the 'text' column\n","df['cleaned_text'] = df['text'].apply(clean_text)\n","\n","# Count the frequency of all words in the dataset\n","word_counts = Counter(' '.join(df['cleaned_text']).split())\n","\n","# Find words that appear more than 3 times\n","common_words = {word for word, count in word_counts.items() if count > 3}\n","\n","# Function to remove infrequent words from text\n","def remove_infrequent_words(text):\n","    words = text.split()\n","    words_filtered = [word for word in words if word in common_words]\n","    return ' '.join(words_filtered)\n","\n","# Apply the function to remove infrequent words\n","df['final_text'] = df['cleaned_text'].apply(remove_infrequent_words)\n","\n","# Save removed words to a CSV file\n","removed_words = {word for word, count in word_counts.items() if count <= 3}\n","removed_words_df = pd.DataFrame(removed_words, columns=['removed_word'])\n","removed_words_df.to_csv('removedwords.csv', index=False)\n","\n","# Save the final cleaned dataset to a new CSV file\n","df[['final_text', 'class']].to_csv('cleaned_train.csv', index=False)\n","\n","print(\"Preprocessing completed. Files saved: 'cleaned_train.csv' and 'removedwords.csv'.\")\n"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":5750706,"sourceId":9459446,"sourceType":"datasetVersion"}],"dockerImageVersionId":30761,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"papermill":{"default_parameters":{},"duration":109.076424,"end_time":"2024-09-23T04:48:33.706705","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-09-23T04:46:44.630281","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}